import os
import subprocess
import sys
import time
import threading
from queue import Queue
from concurrent.futures import ThreadPoolExecutor
import argparse
# ================= âš™ï¸ åŸºç¡€è·¯å¾„é…ç½® =================
# [æ–°å¢] è§£æå‘½ä»¤è¡Œå‚æ•°è·å– Qwen JSON è·¯å¾„
parser = argparse.ArgumentParser(description="Batch Runner")
parser.add_argument("--qwen_json", type=str, required=True, help="Qwen3 ç»“æœæ–‡ä»¶çš„ç»å¯¹è·¯å¾„")
# ä½¿ç”¨ parse_known_args é˜²æ­¢ä¸åç»­å¯èƒ½çš„å‚æ•°å†²çª
args_pre, _ = parser.parse_known_args()

QWEN_RESULT_JSON = args_pre.qwen_json  # <--- è¿™é‡Œå˜æˆäº†åŠ¨æ€å˜é‡

print(f"ğŸ”— [Batch Runner] æ¥æ”¶åˆ°çš„ Qwen JSON è·¯å¾„: {QWEN_RESULT_JSON}")

PROJECT_ROOT = "/opt/data/private/xjx/RailMind/agent/RailwayCARS/relatedResearch/Open-GroundingDino"
LOGS_ROOT = os.path.join(PROJECT_ROOT, "logs", "0113")
OUTPUT_ROOT_BASE = os.path.join(PROJECT_ROOT, "batch_eval_results", "qwen")

# è¯„ä¼°è„šæœ¬è·¯å¾„
EVAL_SCRIPT = "/opt/data/private/xjx/RailMind/agent/RailwayCARS/relatedResearch/Open-GroundingDino/mycode/test/visualize_evaluate_argparse_qwen.py"

# Label Map æ–‡ä»¶è·¯å¾„
LABEL_MAP_FULL = os.path.join(PROJECT_ROOT, "label_map.json")
LABEL_MAP_ONLY = os.path.join(PROJECT_ROOT, "label_map_only.json")

# ================= ğŸ›ï¸ ä»»åŠ¡å¼€å…³ =================

RUN_BENCHMARK  = True 
RUN_TEST_SPLIT = False 

# ================= ğŸ’» æ˜¾å¡é…ç½® (æ–°å¢) =================
AVAILABLE_GPUS = [0, 1, 2, 3]  # ä½ çš„4å¼ å¡ ID
GPU_QUEUE = Queue()
for gpu in AVAILABLE_GPUS:
    GPU_QUEUE.put(gpu)

# çº¿ç¨‹é”ï¼Œé˜²æ­¢å¤šçº¿ç¨‹æ‰“å°æ—¥å¿—æ—¶ä¹±åº
PRINT_LOCK = threading.Lock()

# ================= ğŸ“¦ 1. å¾…è¯„ä¼°çš„æ¨¡å‹åˆ—è¡¨ =================
MODELS_LIST = [
    # "model1_std_fullneg",
    # "model2_std_posonly",
    "model3_only_fullneg",
    "model4_only_posonly",
]

# ================= ğŸ“‚ 2. æ•°æ®é›†è¯¦ç»†é…ç½® =================
BENCHMARK_JSON_PATH = os.path.join(PROJECT_ROOT, "benchmark.json")
TEST_JSON_PATH = os.path.join(PROJECT_ROOT, "test_split_coco.json")

DATASET_CONFIGS = [
    {
        "name": os.path.basename(BENCHMARK_JSON_PATH), 
        "run_flag": RUN_BENCHMARK,
        "json_path": BENCHMARK_JSON_PATH,
        "image_root": "/opt/data/private/xjx/RailMind/database/test/åŸºå‡†æµ‹è¯•_1229/åŸºå‡†æµ‹è¯•æ•°æ®é›†",
        "label_map": LABEL_MAP_ONLY 
    },
    {
        "name": os.path.basename(TEST_JSON_PATH),
        "run_flag": RUN_TEST_SPLIT,
        "json_path": TEST_JSON_PATH,
        "image_root": "/opt/data/private/xjx/RailMind/é«˜é€Ÿé“è·¯æ— äººæœºå›¾åƒ/FilteredLabeled",
        "label_map": LABEL_MAP_FULL
    }
]

# =========================================================

def safe_print(message):
    """çº¿ç¨‹å®‰å…¨çš„æ‰“å°"""
    with PRINT_LOCK:
        print(message)

def run_task(task_args):
    """
    è¿è¡Œå•ä¸ªè¯„ä¼°ä»»åŠ¡ (è¢«çº¿ç¨‹æ± è°ƒç”¨)
    """
    # è§£åŒ…å‚æ•°
    model_folder, dataset_cfg, use_gt_labels = task_args
    
    # --- 1. ç”³è¯· GPU ---
    gpu_id = GPU_QUEUE.get() # å¦‚æœé˜Ÿåˆ—ç©ºäº†ï¼Œè¿™é‡Œä¼šé˜»å¡ç­‰å¾…
    try:
        # 1. å¯»æ‰¾æƒé‡æ–‡ä»¶
        checkpoint = os.path.join(LOGS_ROOT, model_folder, "checkpoint_best_regular.pth")
        if not os.path.exists(checkpoint):
            checkpoint_alt = os.path.join(LOGS_ROOT, model_folder, "checkpoint.pth")
            if os.path.exists(checkpoint_alt):
                safe_print(f"[GPU {gpu_id}] âš ï¸ æç¤º: {model_folder} æ²¡æ‰¾åˆ° best_regularï¼Œä½¿ç”¨ checkpoint.pth ä»£æ›¿")
                checkpoint = checkpoint_alt
            else:
                safe_print(f"[GPU {gpu_id}] âŒ é”™è¯¯: {model_folder} ä¸‹æ‰¾ä¸åˆ°ä»»ä½•æƒé‡æ–‡ä»¶ï¼Œè·³è¿‡...")
                return

        # 2. æ„é€ è¾“å‡ºè·¯å¾„
        dataset_name = dataset_cfg["name"]
        mode_suffix = "GTLabels" if use_gt_labels else "AllLabels"
        
        task_output_dir = os.path.join(OUTPUT_ROOT_BASE, dataset_name, f"{model_folder}_{mode_suffix}")
        log_file = os.path.join(OUTPUT_ROOT_BASE, dataset_name, f"{model_folder}_{mode_suffix}.log")

        if not os.path.exists(task_output_dir):
            os.makedirs(task_output_dir, exist_ok=True)
        
        os.makedirs(os.path.dirname(log_file), exist_ok=True)

        current_label_map = dataset_cfg["label_map"]

        # æ‰“å°å¯åŠ¨ä¿¡æ¯ (ç®€åŒ–ç‰ˆï¼Œé˜²æ­¢åˆ·å±)
        safe_print(f"ğŸš€ [GPU {gpu_id}] å¯åŠ¨: {dataset_name} | {model_folder} | {mode_suffix}")
        
        if not os.path.exists(current_label_map):
            safe_print(f"[GPU {gpu_id}] âŒ é”™è¯¯: Label Map ä¸å­˜åœ¨")
            return
        if not os.path.exists(dataset_cfg['json_path']):
            safe_print(f"[GPU {gpu_id}] âŒ é”™è¯¯: JSON ä¸å­˜åœ¨")
            return

        # 3. æ„é€ å‘½ä»¤
        cmd = [
            "python", EVAL_SCRIPT,
            "--checkpoint_path", checkpoint,
            "--output_dir", task_output_dir,
            "--label_map_file", current_label_map,
            "--test_json_path", dataset_cfg['json_path'],
            "--image_root", dataset_cfg['image_root']
        ]
        
        if use_gt_labels:
            cmd.append("--use_gt_labels_only")
            
            # [ä¿®æ”¹æ ¸å¿ƒé€»è¾‘]ï¼šåªæœ‰åœ¨ Benchmark æ•°æ®é›†ä¸”å¼€å¯ GTLabels (åŸæ„ä¸ºOracleæ¨¡å¼) æ—¶ï¼Œ
            # æ³¨å…¥ Qwen3 çš„ç»“æœä½œä¸º Prompt æ¥æº
            if "benchmark" in dataset_cfg["name"].lower():
                cmd.append("--external_prompt_json")
                cmd.append(QWEN_RESULT_JSON)
                safe_print(f"[GPU {gpu_id}] â„¹ï¸ ä½¿ç”¨ Qwen3 ç»“æœæ›¿æ¢ GT Prompt: {dataset_cfg['name']}")

        # 4. è®¾ç½®ç¯å¢ƒå˜é‡ (æ ¸å¿ƒå¹¶è¡Œé€»è¾‘)
        env = os.environ.copy()
        env["PYTHONPATH"] = PROJECT_ROOT + os.pathsep + env.get("PYTHONPATH", "")
        # æŒ‡å®šè¯¥è¿›ç¨‹åªèƒ½çœ‹åˆ°ç”³è¯·åˆ°çš„è¿™å¼ å¡
        env["CUDA_VISIBLE_DEVICES"] = str(gpu_id)

        # 5. æ‰§è¡Œå‘½ä»¤
        with open(log_file, "w", encoding="utf-8") as f_log:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT, 
                text=True,
                bufsize=1,
                env=env
            )

            for line in process.stdout:
                # å¹¶è¡Œæ—¶ï¼Œä¸å»ºè®®æŠŠæ‰€æœ‰è¾“å‡ºéƒ½ print åˆ°å±å¹•ï¼Œä¼šéå¸¸ä¹±
                # è¿™é‡Œåª print å…³é”®è¿›åº¦æ¡æˆ–æŠ¥é”™ï¼Œæˆ–è€…å¹²è„†åªå†™æ–‡ä»¶
                # ä¸ºäº†ä¿æŒæ¸…çˆ½ï¼Œæˆ‘ä»¬åªæŠŠéè¿›åº¦æ¡ä¿¡æ¯å†™å…¥æ—¥å¿—æ–‡ä»¶
                
                # è¿‡æ»¤é€»è¾‘
                is_progress_bar = ("%|" in line) and (("it/s" in line) or ("s/it" in line) or ("it]" in line))
                if not is_progress_bar:
                    f_log.write(line)
            
            process.wait()

        if process.returncode == 0:
            safe_print(f"âœ… [GPU {gpu_id}] å®Œæˆ: {dataset_name} | {model_folder}_{mode_suffix}")
        else:
            safe_print(f"âŒ [GPU {gpu_id}] å¤±è´¥: {model_folder}_{mode_suffix} (æŸ¥çœ‹æ—¥å¿—)")

    finally:
        # --- ä»»åŠ¡ç»“æŸï¼Œå½’è¿˜ GPU ---
        GPU_QUEUE.put(gpu_id)

if __name__ == "__main__":
    if not os.path.exists(EVAL_SCRIPT):
        print(f"âš ï¸ æ‰¾ä¸åˆ° {EVAL_SCRIPT}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
        sys.exit(1)

    print(f"ğŸ“ ä»»åŠ¡è®¡åˆ’ (4å¡å¹¶è¡Œæ¨¡å¼):")
    print(f"   - Benchmark: {'âœ… å¼€å¯' if RUN_BENCHMARK else 'â¬œ å…³é—­'}")
    print(f"   - TestSplit: {'âœ… å¼€å¯' if RUN_TEST_SPLIT else 'â¬œ å…³é—­'}")

    # 1. æ”¶é›†æ‰€æœ‰ä»»åŠ¡
    all_tasks = []
    for model in MODELS_LIST:
        for dataset in DATASET_CONFIGS:
            if not dataset["run_flag"]:
                continue
            # æ·»åŠ ä»»åŠ¡å‚æ•°åˆ°åˆ—è¡¨
            # all_tasks.append((model, dataset, False)) # AllLabels
            all_tasks.append((model, dataset, True))  # GTLabels

    print(f"ğŸ“Š æ€»å…±ç”Ÿæˆ {len(all_tasks)} ä¸ªä»»åŠ¡ï¼Œå‡†å¤‡å¹¶è¡Œæ‰§è¡Œ...")
    
    # 2. ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
    # max_workers=len(AVAILABLE_GPUS) ç¡®ä¿æœ€å¤šåªæœ‰4ä¸ªä»»åŠ¡åŒæ—¶è·‘
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=len(AVAILABLE_GPUS)) as executor:
        executor.map(run_task, all_tasks)

    end_time = time.time()
    print(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f} ç§’")